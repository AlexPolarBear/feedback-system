{
    "id": 78,
    "field_of_knowledge": "Анализ данных",
    "short_name": "PracticalRL",
    "full_name": "Обучение с подкреплением",
    "size": "большой (2)",
    "description": "https://github.com/yandexdataschool/Practical_RL",
    "direction": "М3–4, НоД3–4, СП3–4, СМ1–2",
    "lecturer_id": 91,
    "year": "2023",
    "context": {
        "reinforcement learning": "reinforcement learning",
        "value-based methods": "value-based methods",
        "model-free RL": "model-free RL",
        "deep RL": "deep RL",
        "exploration": "exploration",
        "policy-based methods": "policy-based methods",
        "sequence models": "sequence models",
        "partially observed MDP": "partially observed MDP",
        "model-based RL": "model-based RL",
        "imitation learning": "imitation learning",
        "optimization": "optimization",
        "decision processes": "decision processes",
        "stochastic optimization": "stochastic optimization",
        "discounted reward": "discounted reward",
        "Q-learning": "Q-learning",
        "SARSA": "SARSA",
        "TD(Lambda)": "TD(Lambda)",
        "pytorch": "pytorch",
        "tensorflow": "tensorflow",
        "experience replay": "experience replay",
        "UCB": "UCB",
        "Thompson Sampling": "Thompson Sampling",
        "policy gradient": "policy gradient",
        "LSTM": "LSTM",
        "GRU": "GRU",
        "planning": "planning",
        "DQN": "DQN",
        "PPO": "PPO",
        "inverse reinforcement learning": "inverse reinforcement learning"
    }
}