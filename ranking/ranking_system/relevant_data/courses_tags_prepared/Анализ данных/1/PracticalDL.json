{
    "id": 77,
    "field_of_knowledge": "Анализ данных",
    "short_name": "PracticalDL",
    "full_name": "Глубокое обучение",
    "size": "большой (2)",
    "description": "https://github.com/yandexdataschool/Practical_DL",
    "direction": "М4, НоД4, СП4",
    "lecturer_id": 91,
    "year": "2023",
    "context": {
        "RL": "RL",
        "MDP": "MDP",
        "Stochastic optimization": "Stochastic optimization",
        "Value-based approach": "Value-based approach",
        "Q-learning": "Q-learning",
        "SARSA": "SARSA",
        "Off-policy Vs on-policy algorithms": "Off-policy Vs on-policy algorithms",
        "TD(Lambda)": "TD(Lambda)",
        "Deep learning 101": "Deep learning 101",
        "Convnets": "Convnets",
        "Infinite/continuous state space": "Infinite/continuous state space",
        "Value function approximation": "Value function approximation",
        "Experience replay": "Experience replay",
        "Double/dueling/bootstrap DQN": "Double/dueling/bootstrap DQN",
        "Contextual bandits": "Contextual bandits",
        "Thompson Sampling": "Thompson Sampling",
        "UCB": "UCB",
        "Bayesian UCB": "Bayesian UCB",
        "Policy-based methods": "Policy-based methods",
        "Policy gradient": "Policy gradient",
        "REINFORCE": "REINFORCE",
        "Advantage actor-critic": "Advantage actor-critic",
        "Recurrent neural networks": "Recurrent neural networks",
        "LSTM": "LSTM",
        "GRU": "GRU",
        "POMDP": "POMDP",
        "Imitation Learning": "Imitation Learning",
        "Inverse Reinforcement Learning": "Inverse Reinforcement Learning",
        "Trust region policy optimization": "Trust region policy optimization",
        "DDPG": "DDPG",
        "Model-Based RL": "Model-Based RL",
        "Planning": "Planning"
    }
}